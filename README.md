# Fragile Visual Short-Term Memory: Feature Encodings of Shapes and Colors

## üìã Research Question

**Does fragile visual short-term memory preserve the detail of higher-order features (e.g., shapes, colors) more accurately than working memory?**

---

## üß† Background & Relevance

Every time we look at a completely new scene, we feel as if we can sense every detail at once; however, our feeling of "seeing everything" is considered an illusion since we have limited capacity to report it when closing our eyes (Naccache, 2018).

### Working Memory (WM)
Our **Working Memory (WM)**‚Äîthe amount of information we can retain at a moment‚Äîis extremely limited and non-detailed.

### Fragile Visual Short-Term Memory (fVSTM)
Recent work has identified **fragile visual short-term memory (fVSTM)** with distinct characteristics:

- **Near-perfect capacity** and contains more detailed images (Sligte et al., 2010)
- **Very fragile and short-lived** compared to standard working memory (Sligte et al., 2008)
- **Outperforms WM** in change-detection tasks
- **Object-based**: harder to recall if the encoding process is interfered with by a similar object rather than a different object (Pinto et al., 2013)

---

### ‚ÄºÔ∏è Research Gap
Little is known about how detailed the features of those objects are encoded:
- Most existing work compares objects that differ **drastically** in their features (e.g., a pink pig vs a red motorbike), potentially making detection easier
- Challenging ideas suggest fVSTM mostly contains **gist-like information**‚Äîlike an instant flash and blurry images (Block, 2011)‚Äîinstead of a clear picture

---

## üí° Hypothesis

1. Since fVSTM is **object-based**, the elementary features (e.g., shape, color) of the object should already be bound and encoded (Logie et al., 2008) to form an object. Therefore, **feature information is already well-encoded by fVSTM**.

2. There is evidence that **orientations** (primarily encoded by V1) are encoded by fVSTM (Pinto et al., 2017). This study emphasizes features formed later along the hierarchy (V2, V4, IT), such as **shapes or colors** (Perry & Fallah, 2014).

3. Since previous research shows fVSTM retains more detailed images, the **feature-encoding of fVSTM will be better than WM**.

4. With practice, participants might also improve at feature and change detection (Arenillas et al., 2003).

---

## üéØ Predictions

This study expects to replicate previous results that **fVSTM is more accurate and has faster response** at detection compared to WM. Furthermore:

- fVSTM will show **higher accuracy** and **faster reaction times** for both shape and color detection than WM
- Participants will generally become **more accurate and react faster** due to practice effects

---

## üî¨ Methods

### Design
**Within-subjects design** adapted from Pinto et al. (2013) and Sligte et al. (2008)

### Independent Variables
1. **Types of memory** (2 levels): fVSTM vs WM
2. **Feature change** (2 levels): Shape vs Color

### Dependent Variables
1. **Accuracy**: Percentage of correct responses for change detection and feature detection
2. **Reaction time (ms)**: Time taken to respond
   - For fVSTM: Measured from the onset of the second list
   - For WM: Measured from the disappearance of the cue

---

## üß™ Experimental Procedure

### Blocks and Trials
- **1 practice block** (10 trials)
- **4 test blocks** (80 trials each)
- **1 trial duration**: 7-9 seconds

### Stimuli Specifications

#### Shapes
- **Square**: 50√ó50 px, line width = 5 px
- **Circle**: radius = ‚àö(2500 / œÄ) px (equal area to square), line width = 5 px

#### Colors
- **Green**: RGB (0, 1, 0)
- **Blue**: RGB (0, 0, 1)

#### Display Configuration
- **First appearance**: 8 items (squares/circles, green/blue) arranged around an imaginary circle (r = 300px). Each feature type appears at least 3 times
- **Second appearance**: One stimulus either stays or changes by shape (circle ‚Üî square) or color (blue ‚Üî green)
- **Background**: Black RGB (0, 0, 0)
- **Fixation point**: White circle, radius = 6 px, centered
- **Cue**: White filled arrow, length = 0.7 √ó 300 px, pointing to target stimulus

#### Keyboard Responses
- **'z' key**: change/shape
- **'m' key**: stay/colors

### Trial Sequence

#### fVSTM Condition
```
First display (250 ms) ‚Üí Blank (1000 ms) ‚Üí Cue (500 ms) ‚Üí Blank (500 ms) ‚Üí Second display (change/stay) until response ‚Üí Response
```

#### WM Condition
```
First display (250 ms) ‚Üí Blank (1000 ms) ‚Üí Second display (changed/unchanged) until response + Cue (500 ms) ‚Üí Response ‚Üí If correct: feature change question ‚Üí Response
```

**Note**: In both conditions, if change is correctly identified, participants indicate whether the change was in shape or color. Incorrect responses receive immediate feedback and skip to next trial.

---

## üìö References

- Arenillas, J. F., Molina, C. A., Chacon, P., Egido, J. A., & Alvarez, A. (2003). Cerebral microbleeds and intracerebral haemorrhage in patients receiving antithrombotic therapy. *The Lancet Neurology, 2*(11), 692‚Äì697. https://doi.org/10.1016/S1474-4422(02)00236-3

- Baddeley, A. (2020). Working memory. In *Routledge eBooks* (pp. 71‚Äì111). https://doi.org/10.4324/9780429449642-4

- Block, N. (2011). Perceptual consciousness overflows cognitive access. *Trends in Cognitive Sciences, 15*(12), 567‚Äì575. https://doi.org/10.1016/j.tics.2011.10.001

- Logie, R. H., Brockmole, J. R., & Vandenbroucke, A. R. E. (2008). Bound feature combinations in visual short-term memory are fragile but influence long-term learning. *Visual Cognition, 17*(1‚Äì2), 160‚Äì179. https://doi.org/10.1080/13506280802228411

- Naccache, L. (2018). Why and how access consciousness can account for phenomenal consciousness. *Philosophical Transactions of the Royal Society B Biological Sciences, 373*(1755), 20170357. https://doi.org/10.1098/rstb.2017.0357

- Perry, C. J., & Fallah, M. (2014). Feature integration and object representations along the dorsal stream visual hierarchy. *Frontiers in Computational Neuroscience, 8*. https://doi.org/10.3389/fncom.2014.00084

- Pinto, Y., Sligte, I. G., Shapiro, K. L., & Lamme, V. A. F. (2013). Fragile visual short-term memory is an object-based and location-specific store. *Psychonomic Bulletin & Review, 20*(4), 732‚Äì739. https://doi.org/10.3758/s13423-013-0393-4

- Pinto, Y., Vandenbroucke, A. R., Otten, M., Sligte, I. G., Seth, A. K., & Lamme, V. A. F. (2017). Conscious visual memory with minimal attention. *Journal of Experimental Psychology General, 146*(2), 214‚Äì226. https://doi.org/10.1037/xge0000255

- Priebe, N. J. (2016). Mechanisms of orientation selectivity in the primary visual cortex. *Annual Review of Vision Science, 2*(1), 85‚Äì107. https://doi.org/10.1146/annurev-vision-111815-114456

- Sligte, I. G. (2010). Detailed sensory memory, sloppy working memory. *Frontiers in Psychology, 1*. https://doi.org/10.3389/fpsyg.2010.00175

- Sligte, I. G., Scholte, H. S., & Lamme, V. A. F. (2008). Are there multiple Visual Short-Term Memory Stores? *PLoS ONE, 3*(2), e1699. https://doi.org/10.1371/journal.pone.0001699

- Vandenbroucke, A. R., Sligte, I. G., & Lamme, V. A. (2011). Manipulations of attention dissociate fragile visual short-term memory from visual working memory. *Neuropsychologia, 49*(6), 1559‚Äì1568. https://doi.org/10.1016/j.neuropsychologia.2010.12.044

---

## üìä Project Status

This repository contains the research proposal and experimental design for investigating feature encoding in fragile visual short-term memory.

## üìß Contact

For questions or collaboration inquiries, please open an issue in this repository.
